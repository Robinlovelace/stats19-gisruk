---
title: "Reproducible road safety research: an exploration of the shifting spatial and temporal distribution of car-pedestrian crashes"
author:
- Dr Robin Lovelace --- University of Leeds, Consumer Data Research Centre (CDRC) and Institute for Transport Studies (ITS) and Leeds Institute for Data Analytics (LIDA)
- Dr Layik Hama --- University of Leeds, Consumer Data Research Centre (CDRC) and Leeds Institute for Data Analytics (LIDA)
- Dr Roger Beecham --- University of Leeds, School of Geography, Consumer Data Research Centre (CDRC) and Leeds Institute for Data Analytics (LIDA)
date: '`r Sys.Date()`'
output:
  github_document
  # pdf_document:
  #  fig_caption: yes
  # number_sections: true
bibliography: references.bib
---

```{r, include=FALSE, eval=FALSE}
file.rename("README.pdf", "stats19-gisruk.pdf")
```




# Summary {-}

This paper demonstrates a reproducible approach to downloading, formatting and analysing road crash data.
Building on the recently released **stats19** R package, it is based on a dataset of half a million incidents (78,448 car-pedestrian crashes) from the UK STATS19 database, from 2013 to 2017.
The analysis reveals variability in crash characteristics depending on social, environmental and regulatory factors, and variable police force performance in terms of 'risk ratios' over time.
Geographic 'small multiple' visualisations show the potential of the approach to feed into interactive dashboards and maps to inform road safety policy, suggesting multiple directions for reproducible road safety research.

<!-- Authors are requested to keep to the word limit of 1500 words. The word limit includes the main body of the abstract and everything within (including captions etc.,) and the references. Not included in the word count is the title, author list, date, summary, keywords and author biographies -->

**Keywords:** geographic analysis, road safety, reproducibility

# Introduction

This paper is motivated by two high-level policy and academic objectives, which intersect.
The policy objective is to provide high quality evidence and the 'best available data' in an 'actionable' form.
The academic objective is to ensure that research findings can be reproduced, to ensure scientific falsifiability and encourage cooperation between researchers.
These two objectives intersect because without reproducible methods it is difficult to generate high quality evidence that can be externally verified.
Conversely, an academic environment that is conducive to collaboration and not competition requires a government that supports 'open science', "the transparent and accessible knowledge [and methods] shared and developed through collaborative networks" [@vicente-saez_open_2018].

This context is relevant to many fields of research that have practical and policy implications. Road safety research is no exception, as its findings often have direct policy implications and can be highly emotive, raising questions about the divide between research and policy [@elvik_handbook_2009]:

> Can science and politics be kept apart in such a
highly applied field of research? Where is the dividing line between science and politics
in road safety?

More specifically, how can road safety research become more reproducible?
This would clearly have advantages for many stakeholders: local and national governments would be better equipped to justify their road safety policies if the evidence on which they are based is the result of reproducible research conducive to 'citizen science' [@bonney_next_2014]; 
advocacy groups such as RoadPeace would be able to engage not only in lobbying, but also science, encouraging arguments from all sides to be based more on objective evidence, rather than emotive anecdote;
and citizens themselves should benefit, from better road safety policies and the educational opportunities created by open science.

A more mundane motivation was that dozens of researchers are duplicating effort by cleaning road crash data, a process first undertaken by one of the authors three years ago [@lovelace_who_2016] (the code used to clean the data can still be found on [GitHub](https://github.com/Robinlovelace/bikeR)).
The problem is that the official source of road crash data, called STATS19 [@STATS19Data], is provided in a series of opaque `.csv` files, which provide only integer values.
This has meant that, instead of pooling data cleaning resources and focussing on the data analysis and research, much time is spent doing data cleaning, duplicating previous work.
To solve this problem, the **stats19** package was developed, which automatically downloads and formats STATS19 data.
Written in the popular statistical programming language R [@rcore], **stats19** was published on the Comprehensive R Archive Network (CRAN) in January 2019 [@lovelace_stats19_2019].

**stats19** can convert the non-geographic data into a geographic representation of the crashes, an important feature given that much recent road safety research has been conducted using Geographic Information Systems (GIS) software [e.g. @kim_using_1996; @peled_pc-oriented_1993; @steenberghen_intra-urban_2004;@razzak_application_2011].
With the growth of open source GIS products such as QGIS, this is a trend that can encourage open science, as defined above.
A limitation of dedicated GIS software products from a reproducibility perspective, however, is that they tend to be based on a graphic user interface (GUI), rather than a command-line interface (CLI).
This has led to many efforts to push geographic research in more reproducible and computational directions, under labels such as Geographic Information Science (GIScience), Geographic Data Science, and Geocomputation [@lovelace_geocomputation_2019].

<!-- On a practical level, the work detailed in this paper is indicative of reproducible worklflows because it uses code to define the geographic analysis steps undertaken and a stanardised API for accessing and processing data (**stats19** R package) [@lovelace_stats19_2019], allowing findings to be externally verified. -->
This paper 'practices what it preaches' in terms of reproducibility:
code chunks in 'RMarkdown' (`.Rmd` files) run each time the document is compiled [@xie_r_2018].
Thus, beyond the high-level aims of evidence-based policy and reproducible research, this paper has a more specific purpose:
to demonstrates that geographic road safety research *can* (and probably usually *should*) now be reproducible.
<!-- with an example that presents new findings on the shifting spatial distribution of car-pedestrian crashes at the national level over the last 5 years. -->


# Set-up and data preparation

<!-- We include an example of how to access, process and briefly analyse data _within this paper_, to demonstrate the importance of such initiatives for enabling replication of methods, validation of findings and, subsequently, cumulative knowledge building. -->

As with many computational tasks, the first stage is to install and load the necessary software.
This is done in the code chunk below which, when run from an R console (CLI), installs and loads as the key packages used:

```{r}
pkgs = c(
  "tidyverse",
  "sf",
  "stats19",
  "tmap"
)
```

```{r, eval=FALSE}
install.packages(pkgs)
purrr::map_lgl(pkgs, require, character.only = TRUE)
```

```{r, echo=FALSE, message=FALSE}
setNames(purrr::map_lgl(pkgs, require, character.only = TRUE), pkgs)
```

The following code downloads, formats and combines crash data over the past 5 years:^[
Note: the code following code chunks on this page are time-consuming and require interactive use of R.
To save time, we recommend that readers who wish to reproduce the results start by downloading the `a_cpj` dataset which is available, alongside other datasets from the processing stage, from https://github.com/Robinlovelace/stats19-gisruk/releases
]


```{r cached1, cache=TRUE, message=FALSE, eval=FALSE}
y = 2013:2017
a = map_dfr(y, get_stats19, type = "accidents")
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(a, "./a.Rds")
```

```{r, echo=FALSE}
# saveRDS(a_sample, "documents/gisruk/a_sample.Rds")
download.file("https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/a_sample.Rds", 
"a_sample.Rds")
```

The resulting dataset is large, consisting of more than half a million
<!-- (`r # format(nrow(a), big.mark = ",")`) -->
(691,641)
rows (crash points), with `r # ncol(a)` 31 columns [see @lovelace_stats19_2019 for details on the data].
This is easy to work with in-memory on modern computers, though consumes 1/3 GB of RAM.
These can be converted into a spatial class, defined by the **sf** package [@pebesma_simple_2018].
A sample of 1000 records is taken and plotted, for demonstration purposes, as follows (see the resulting Figure 1):

```{r, eval=FALSE}
a_sf = format_sf(a)
a_sample = a_sf %>% sample_n(1000)
```

```{r uk-plot1, cache=TRUE, fig.cap="Columns of 'a_sample' variable plotted separately on a UK map.", warning=FALSE, fig.height=4}
a_sample = readRDS("a_sample.Rds")
plot(a_sample)
```

Having gained a measure of the crash data, and some key descriptive statistics, we can proceed to join-on the associated casualty and vehicle tables.
The following command uses the argument `type` to specify which table from the STATS19 schema is to be read-in:

```{r, eval=FALSE}
c = map_dfr(y, get_stats19, type = "casualties")
v = map_dfr(y, get_stats19, type = "vehicle")
```

```{r, echo=FALSE, cache=TRUE, eval=FALSE}
# note: previous line must be done interactively
piggyback::pb_download("a.Rds")
piggyback::pb_download("c.Rds")
piggyback::pb_download("v.Rds")
a = readRDS("a.Rds")
c = readRDS("c.Rds")
v = readRDS("v.Rds")
```


We are interested in accidents in which a pedestrian was injured and where the (only) vehicle involved was a car.
This subset of the casualties dataset can be extracted as follows:

```{r, eval=FALSE}
c_ped = c %>% filter(casualty_type == "Pedestrian")
v_car = v %>% filter(vehicle_type == "Car")
a_cp = a_sf %>%
  filter(number_of_vehicles == 1 & number_of_casualties == 1) %>% 
  filter(accident_index %in% c_ped$accident_index) %>% 
  filter(accident_index %in% v_car$accident_index)
```

```{r, eval=FALSE, echo=FALSE}
nrow(a_cp) / nrow(a)
```

Before proceeding, we join the vehicle and crash tables onto the crash data as follows, to create the main input dataset used in this paper:
<!-- , keeping only records in which casualty *and* vehicle data is present. -->

```{r, eval=FALSE}
a_cpj = a_cp %>% 
  inner_join(v_car) %>% 
  inner_join(c_ped)
```

```{r, echo=FALSE}
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/a_cpj.Rds"
f = "a_cpj.Rds"
if(!file.exists(f)) download.file(url = u, destfile = f)
# file.copy("documets/gisruk/a_cpj.Rds", "a_cpj.Rds")
# piggyback::pb_upload("a_cpj.Rds")
# piggyback::pb_download("a_cpj.Rds")
# file.copy("a_cpj.Rds", "documets/gisruk/a_cpj.Rds")

# saveRDS(a_cpj, "documents/gisruk/a_cpj.Rds")
a_cpj = readRDS("a_cpj.Rds")
# a_cpj = readRDS("documents/gisruk/a_cpj.Rds")
```

The resulting dataset, `a_cpj`, contains 78,454 rows: 11% of the crashes in the original dataset represent a car-pedestrian collision involving a single vehicle and a single casualty (the pedestrian).
This dataset, which contains 68 columns, will be used for the remainder of this analysis, and can be downloaded from the paper's GitHub repo and loaded as follows:

```{r, eval=FALSE}
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/a_cpj.Rds"
download.file(url = u, destfile = "a_cpj.Rds")
a_cpj = readRDS("a_cpj.Rds")
```

The final code chunk in this section generates plots that expose insight into the nature of car-pedestrian crashes.
As illustrated in Figures 2 and 3, the results match prior expectations: 
elderly people (in the 66-75 and 75+ age bands) and fast roads (40 to 70 miles per hour) tend to result in more serious and fatal injuries.

```{r, echo=FALSE}
a_cpj$impact = a_cpj$first_point_of_impact
a_cpj$impact[grepl(pattern = "missing|not", x = a_cpj$impact)] = "Other"
a_cpj$age_band_of_casualty[a_cpj$age_band_of_casualty == "6 - 10"] = "06 - 10"
```


```{r}
g = ggplot(a_cpj)
```

```{r, eval=FALSE}
g + geom_bar(aes(accident_severity, fill = urban_or_rural_area)) +
 facet_wrap(vars(speed_limit), scales = "free_y") +
  labs(fill = "Location")

g + geom_bar(aes(accident_severity, fill = impact)) +
  facet_wrap(vars(age_band_of_casualty), scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45))
```


```{r, fig.cap="Crash severity by speed limit (top) and crash severity by age band of casualty (bottom)", fig.height=6, message=FALSE, echo=FALSE}
p1 = g + geom_bar(aes(accident_severity, fill = urban_or_rural_area)) +
 facet_wrap(vars(speed_limit), scales = "free_y") +
  labs(fill = "Location")
p2 = g + geom_bar(aes(accident_severity, fill = impact)) +
  facet_wrap(vars(age_band_of_casualty), scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45))
devtools::install_github("thomasp85/patchwork")
library(patchwork)
p1 + p2 + plot_layout(ncol = 1, heights = c(4, 5))
```

```{r, eval=FALSE, echo=FALSE}
# base R plotting
barplot(table(a_cpj$accident_severity))
```

\newpage

# Geographic analysis and results

The data is still in a spatial form, of class `sf`, enabling geographic analysis.
Although the geographic resolution of the data is high, ~10 m, we will analyse it at the national level, to investigate the relative performance of different police forces over time.
A geographic join will be used to assign a police force to each crash (although police force is already a variable in the dataset):

```{r}
agg_slight = aggregate(a_cpj["accident_severity"], police_boundaries,
                      function(x) sum(grepl(pattern = "Slight", x)))
```


```{r, echo=FALSE, fig.cap="Overview of crashes by police force area, showing relative numbers of slight, serious and fatal injuries.", message=FALSE}
agg_severe = aggregate(a_cpj["accident_severity"], police_boundaries,
                      function(x) sum(grepl(pattern = "Serious", x)))
agg_fatal = aggregate(a_cpj["accident_severity"], police_boundaries,
                      function(x) sum(grepl(pattern = "Fatal", x)))
agg_none = agg_slight[0]
agg_all = agg_none
agg_all$slight = agg_slight$accident_severity
agg_all$serious = agg_severe$accident_severity
agg_all$fatal = agg_fatal$accident_severity
b = 10^(-1:5)
tm_shape(agg_all) +
  tm_polygons(c("slight", "serious", "fatal"), palette = "viridis", breaks = b)

```

Repeating this process for each crash severity type results in the plot presented in Figure 3.
Because a log scale is used between the different crash categories, the results shown in Figure 3 shows that, outside London, serious and fatal crashes are comparatively common in some areas.
We can identify which police forces have the highest *ratios* of crashes that are reported as fatal.
The top 5 and bottom 5 are shown in Table 1, which shows wide variability.
As would be expected, large cities (where average speeds tend to be low) tend to have a relatively low percentage of car-pedestrian casualties that are fatal, whereas predominantly rural forces such as Wiltshire and Gloucestershire (where the roads tend to be faster, and there are fewer crashes overall) have a relatively high proportion that are fatal.
Devon and Cornwall is an outlier: a relatively rural force with a low proportion of fatalities.
Further research could seek to explore the reasons for this variability.

```{r, echo=FALSE}
agg_all$name = police_boundaries$pfa16nm
agg_names = agg_all %>% 
  mutate(percent_fatal = fatal / (slight + serious + fatal) * 100)
# mapview::mapview(agg_names) # verification
top_n = agg_names %>% 
  arrange(desc(percent_fatal)) %>% 
  top_n(5, percent_fatal) %>% 
  st_drop_geometry() %>% 
  dplyr::select(name, slight, serious, fatal, percent_fatal)

bottom_n = agg_names %>% 
  arrange(desc(percent_fatal)) %>% 
  top_n(-5, percent_fatal) %>% 
  st_drop_geometry() %>% 
  dplyr::select(name, slight, serious, fatal, percent_fatal)

na_df = matrix(data = NA, nrow = 1, ncol = ncol(bottom_n)) %>% 
  as.data.frame()
names(na_df) = names(bottom_n)

top_bottom = bind_rows(top_n, na_df, bottom_n)
knitr::kable(top_bottom, digits = 1, caption = "Top and bottom 5 police forces in terms of the percentage of car-pedestrian crashes that are fatal.")
```

\newpage

What about variability *over time*?
The overall trend in the number of pestrians hit by cars can be seen in Figure 4, which shows the total number of people by month, broken-down by crash severity.
This result shows that pedestrian casualty rates have essentially flat-lined over the past 5 years, after decades of improvement.
What the data does not show, however, is the geographic breakdown of these trends.

```{r, echo=FALSE, fig.cap="Variability of crash rates over time." }
a_cpj$year = lubridate::year(a_cpj$date)
a_cpj$month = lubridate::month(a_cpj$date)
a_cpj$pct_yr = a_cpj$month / 13
a_cpj$year_month = a_cpj$year + a_cpj$pct_yr
a_time = a_cpj %>% 
  st_drop_geometry() %>% 
  group_by(year_month, casualty_severity) %>% 
  summarise(n = n())
ggplot(a_time) +
  geom_line(aes(year_month, n, lty = casualty_severity)) +
  scale_y_log10()
```

A geographic join can assign each crash to a police authority as follows:

```{r}
a_cps = st_join(a_cpj, police_boundaries)
```

The new object has the variable `pfa16nm`, the police force name, which can be subsequently aggregated and then joined back onto the geographic variable of `police_boundaries`.
Before we plot the 'best' and 'worst' performers geographically, it is worth investigating the temporal trend of the top and bottom forces in terms of the percentage of casualties that were fatal (see Table 1). When disaggregated by force area (Figure 5), the incidence of fatalities is too low for reliable analysis over time. However, the results  suggest that London (controlled by the Metropolitan Police) has seen an increase in serious, and to a lesser extent slight, pedestrian casualties since around the beginning of 2016.
<!-- Lancaster has seen an increase in the number of fatalities per month, beginning around the same time. -->
These raise the question: why?
Rather than answer this question, the final analysis will explore the geographic distribution of improving/worsening performance by force area using geographically arranged small multiples [@tufte_visual_1983].

```{r, echo=FALSE, message=FALSE, fig.cap="Average number of pedestrian casualties by severity and police force in a selection of areas (see Table 1)"}
a_cps$year = lubridate::year(a_cps$date)
a_cps$month = lubridate::month(a_cps$date)
a_cps$pct_yr = a_cps$month / 13
a_cps$year_month = a_cps$year + a_cps$pct_yr
# a_cps$quarter = lubridate::quarter(a_cps$date, with_year = TRUE)
a_cps_sub = a_cps[a_cps$pfa16nm %in% top_bottom$name[7:10], ]
a_time = a_cps_sub %>% 
  st_drop_geometry() %>% 
  group_by(year_month, pfa16nm, casualty_severity) %>% 
  summarise(n = n())
ggplot(a_time) +
  geom_smooth(aes(year_month, n, col = pfa16nm)) +
  facet_wrap(vars(casualty_severity), scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45))
  
```

\newpage

We have identified some challenges associated with disaggregate analysis of casualty data: the substantial between-force differences in absolute casualty numbers and the problem of reliably identifying temporal patterns in low incidence events such as fatalities. One measure that might allow traction on the _relative severity_ of accidents occuring in force areas is the killed and seriously-injured rate (KSI rate) -- the number of casualties that involved a fatality or serious injury as a proportion of all casualties.  Analysing year-on-year change in KSI rates over the 5-year period, there appears to be a slight recent upward trend: from $0.22$ in 2013-2015, to $0.23$ in 2016 and $0.25$ in 2017. A principled way of exploring the extent to which particular force areas are over- or under- represented in their KSI rates is by calculating risk ratios for each force ($RR_{f}$), expressing the KSI rate for the force ($ksi_f$) as a ratio of the national KSI rate ($ksi_{nat}$): $RR_f=ksi_f/ksi_{nat}$, where a value $>1.0$ indicates a higher KSI rate than nationally and a value $<1.0$ indicates a KSI rate lower than the national average rate. In order to analyse year-on-year change in these force-level risk ratios and the raw KSI rates, we generate sets of small multiple charts per force, arranged according to their approximate geographic position (e.g. Figure 6) using the layout algorithm published in @meulemans_small_2017.  The first two maps in Figure 7 are choropleth maps displaying a single risk ratio statistic representing all 5 years of data; the final map supports year-on-year comparison by representing raw KSI rates as a line, with risk-ratios for each year as coloured bars.  


```{r, echo=FALSE, eval=FALSE, message=FALSE}
pkgs = c("gganimate","ggmosaic","rmapshaper")
install.packages(pkgs)
purrr::map_lgl(pkgs, require, character.only = TRUE)
setNames(purrr::map_lgl(pkgs, require, character.only = TRUE), pkgs)

theme_set(theme_minimal(base_family="Avenir Book"))
# Data : 78,454 records representing a car-pedestrian collision involving a single vehicle and a single casualty.
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/a_cpj.Rds"
f = "a_cpj.Rds"
if(!file.exists(f)) download.file(url = u, destfile = f)
a_cpj = readRDS("a_cpj.Rds")

# Convenience function for rescaling
map_scale = function(value, min1, max1, min2, max2) {
  return  (min2+(max2-min2)*((value-min1)/(max1-min1)))
}
# Load datasets created by generate_semispatial.R
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/grid_sf.Rds"
f = "grid_sf.Rds"
if(!file.exists(f)) download.file(url = u, destfile = f)
grid_sf = readRDS("grid_sf.Rds")
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/real_sf.Rds"
f = "real_sf.Rds"
if(!file.exists(f)) download.file(url = u, destfile = f)
real_sf = readRDS("real_sf.Rds")
u = "https://github.com/Robinlovelace/stats19-gisruk/releases/download/0.0.1/grid_real_sf.Rds"
f = "grid_real_sf.Rds"
if(!file.exists(f)) download.file(url = u, destfile = f)
grid_real_sf = readRDS("grid_real_sf.Rds")

# Choropleth of risk ratio.
#data
rr_choropleth = real_sf %>% left_join(
  a_cpj %>%
  mutate(is_slight=if_else(accident_severity=="Slight",1,0)) %>%
  group_by(police_force) %>%
    summarise(accident_count=n(), rr_f=(1-(sum(is_slight))/accident_count)/ksi_nat),
  by=c("region"="police_force")) %>% 
#plot
  ggplot()+
  geom_sf(aes(fill=rr_f), colour="#636363", size=0.05)+ 
  coord_sf(datum=NA)+
  scale_fill_distiller(palette = "RdBu", direction=-1, limits=c(0.6,1.4))+
  guides(fill=guide_colourbar(title="RR"))+
  labs(subtitle="Risk ratio by force area 2013-17")+
  theme(
    legend.position = "bottom"
  )

# Semi-spatial grid of risk ratios.
# data
rr_grid = a_cpj %>%
  mutate(year= lubridate::year(date), is_slight=if_else(accident_severity=="Slight",1,0)) %>%
  mutate(is_slight=if_else(accident_severity=="Slight",1,0)) %>%
  group_by(police_force) %>%
    summarise(accident_count=n(), rr_f=(1-(sum(is_slight))/accident_count)/ksi_nat) %>%
  left_join(grid_layout, by=c("police_force"="region")) %>% 
  #filter Scottish forces and City of London
  filter(!is.na(x), police_force!="City of London") %>% 
  add_row(police_force="", accident_count=NA, rr_f=NA, id=0, x=1,y=1, region_abb="", east=0, north=0,type="grid") %>%
#plot
ggplot()+
geom_rect(aes(xmin=0,xmax=1,ymin=0,ymax=1), colour="#636363", fill="transparent", size=0.1)+
geom_rect(aes(xmin=0.05,xmax=0.95,ymin=0.05,ymax=0.95, fill=rr_f), colour="#636363", size=0.1)+
geom_text(aes(x=0.5, y=0.5, label=region_abb), size=3, colour="#252525", alpha=0.9, show.legend=FALSE, family="Avenir Book")+
 scale_fill_distiller(palette = "RdBu", direction=-1, limits=c(0.6,1.4))+
labs(subtitle="Risk ratio by force area 2013-17")+
 guides(fill=guide_colourbar(title="RR"))+
 facet_grid(y~x)+
  theme(
    legend.position = "bottom",
    axis.title=element_blank(),
    axis.text=element_blank(),
    panel.grid=element_blank(),
    strip.text=element_blank(),
    panel.spacing=unit(-0.2, "lines")
  )

# Semi-spatial grid of risk ratios over time.
#data
rr_grid_cot = a_cpj %>%
  mutate(year= lubridate::year(date), is_slight=if_else(accident_severity=="Slight",1,0)) %>%
  group_by(year) %>%
    mutate(accident_count=n(), ksi_rate_nat=(1-(sum(is_slight))/accident_count)) %>% ungroup() %>%
  group_by(police_force, year) %>%
    summarise(accident_count=n(), ksi_rate=(1-(sum(is_slight))/accident_count), rr_f=ksi_rate/first(ksi_rate_nat)) %>%
  left_join(grid_layout, by=c("police_force"="region")) %>% 
  #filter Scottish forces and City of London
  filter(!is.na(x), police_force!="City of London") %>%  ungroup() %>%
  add_row(police_force="", year=2013,accident_count=NA, ksi_rate=NA, rr_f=NA, id=0, x=1,y=1, region_abb="", east=0, north=0,type="grid") %>%
#plot
ggplot()+
geom_rect(aes(xmin=2012.3,xmax=2017.7,ymin=0,ymax=0.375), colour="#636363", fill="#ffffff", size=0.1)+
 geom_crossbar(aes(x=year,y=0.35, ymin=0.015, ymax=0.36, fill=rr_f), linetype=0)+
 geom_line(aes(x=year,y=ksi_rate))+
 scale_y_continuous(limits=c(0,0.375))+
 scale_fill_distiller(palette = "RdBu", direction=-1, limits=c(0.35,1.75))+
labs(subtitle="Risk ratio by force area 2013-17, year-on-year analysis")+
 guides(fill=guide_colourbar(title="RR"))+
 facet_grid(y~x)+
  theme(
    legend.position = "bottom",
    axis.title=element_blank(),
    axis.text=element_blank(),
    panel.grid=element_blank(),
    strip.text=element_blank(),
    panel.spacing=unit(-0.2, "lines")
  )

# We need to assemble these ggplot2 objects in a single view.
# The gridExtra package supports this view composition.
install_packages("gridExtra")
library(gridExtra)
out = grid.arrange(rr_choropleth, rr_grid, rr_grid_cot,
                    widths = c(0.33, 0.33, 0.33), heights=c(0.1, 0.8, 0.1),
                    layout_matrix = rbind(c(NA,NA,NA), c(1,2,3), c(NA,NA,NA)))

# Save output as a .png to your local directory
ggsave("./risk_ratio_maps2.png",plot = out, width=14, height=7)
```

```{r geo-layout, fig.cap="An approximate geographical layout of England and Wales police force areas following the layout algorithm published in Muelmans et al. (2017).", echo=FALSE, out.width="100%"}
knitr::include_graphics("semispatial_layout.png")
```

```{r rr, fig.cap="Risk ratios of KSI rates by force area, from 2013 to 2017 (left and middle), with year-on-year trend in risk ratios and raw KSIs (right).", echo=FALSE, out.width="100%"}
knitr::include_graphics("risk_ratio_maps.png")
```



<!-- When the analysis presented in Figure 5 is conducted for *all* police jurisdictions, and an aggregate measure of 'direction of trend' is used (in this case, average increase/decrease in counts of crashes of different severity levels per year) is used, we can see the spatial distribution of improvement in casualty numbers across the country (see Figure 6). -->
<!-- It is clear that, assuming crash counts are a good metric of safety (which may not always hold, but is sufficient for the purposes of this paper), some areas perform much better than others. -->
<!-- In terms of fatal car-pedestrian crashes, it is clear that large regions including West Yorkshire, Greater Manchester and Northumbria are not performing well. -->
<!-- The trend for serious car-pedestrian crashes is even more mixed, with London and regions to the east (including Kent and Essex), seeing substantial upward trends in the number of pedestrians sersiously hurt in car crashes. -->

<!-- ```{r, echo=FALSE, fig.cap="Trend in car-pedestrian casualties by region, 2013 to 2017, in units of average number of additional casualties per year, by severity of injuries.", message=FALSE} -->
<!-- region = "Lancashire" -->
<!-- sev = "Fatal" -->
<!-- sel = a_cps$pfa16nm == region -->
<!-- a_cps_sub1 = a_cps[sel, ] -->
<!-- a_agg = a_cps %>%  -->
<!--   st_drop_geometry() %>%  -->
<!--   group_by(pfa16nm, year) %>%  -->
<!--   summarise( -->
<!--     Fatal = sum(casualty_severity == "Fatal"), -->
<!--     Serious = sum(casualty_severity == "Serious"), -->
<!--     Slight = sum(casualty_severity == "Slight") -->
<!--     ) -->
<!-- a_cor = a_agg %>%  -->
<!--   group_by(pfa16nm) %>%  -->
<!--   summarise( -->
<!--     Fatal = lm(Fatal ~ year)$coefficients[2], -->
<!--     Serious = lm(Serious ~ year)$coefficients[2], -->
<!--     Slight = lm(Slight ~ year)$coefficients[2] -->
<!--     ) -->
<!-- agg_cor = left_join(police_boundaries, a_cor) -->
<!-- a_highlight = filter(police_boundaries, pfa16nm %in% top_bottom$name[7:10]) -->
<!-- a_highlight$nm = stringr::str_sub(string = a_highlight$pfa16nm, start = 1, end = 3) -->
<!-- b = c(60, 5, 1, 0) -->
<!-- bb = c(-b, b[3:1]) -->
<!-- tm_shape(agg_cor) + -->
<!--   tm_fill(c("Fatal", "Serious", "Slight"), palette = "-Spectral", alpha = 0.8, breaks = bb) + -->
<!--   tm_borders() + -->
<!--   tm_shape(a_highlight) + -->
<!--   tm_borders(col = "blue", lwd = 2, alpha = 0.4) + -->
<!--   tm_text("nm")  -->
<!--   # tm_layout(legend.outside = T) -->
<!-- ``` -->

# Discussion

This paper has provided a taster of what is possible with open road crash data, using packages such as **stats19**, revealing regional differences in the numbers, proportions and trends of one particular type of road crash: car-pedestrian collisions.
However, much more is possible with the approach. 
A key priority in road safety research is to identify suitable denominators of risk, something that geographical methods are well-suited to answering.
With new data sources, could denominators be produced at high levels of geographic resolution than the coarse Local Authority levels used in a previous studies [@lovelace_who_2016]?
More specifically, why have there been increases in serious and fatal casualties in some areas, as shown in the previous section?
This finding is concerning, especially in the context of the government's commitment to contribute to the European Union's target of halving road traffic deaths by 2050,^[
https://fleetworld.co.uk/uk-falling-behind-on-road-safety-targets/
] and recent concerns from road safety advocates about recent trends in road traffic deaths.^[
http://www.brake.org.uk/facts-resources/1653-uk-road-casualties
]

The richness of road crash data means that it can be disaggregated in many ways, beyond the results presented in this paper: there are 50+ columns and hundreds of thousands of roads represented in the joined STATS19 data, suggesting future research questions, including:
- What kinds of places have seen improvements in road safety, and how can we learn from these?
- Can automated summary graphics provide insight into performance and early warnings of increases in certain types of crashes?
- And can recent findings about the effectiveness of different interventions, particuarly around 20 mph zones and limits [@grundy_effect_2009; @aldred_cycling_2018] be replicated using open data and publicly available code?

From a GIS perspective, the data presented in this paper are of interest in terms of their size (there are several million points in the open STATS19 data, going back to 1979), richness and spatial resolution (in the order of 10m, but how accurate are the coordinates?).
One area where geographic research can help is in data visualisation, with new packages such as **geoplumber** opening the possibility of open source web applications, building on sites such as [www.crashmap.co.uk](https://www.crashmap.co.uk/) and [www.pct.bike](http://www.pct.bike/) to inform policy and public debate [@lovelace_propensity_2017].
More theoretical directions are suggested by the complex processes underlying crash data (point patterns on a linear network).
However, while hundreds people die on the roads each year in the UK (1676 people in 2017, 3 deaths per 100,000) and worldwide (1,250,000  people in 2015, 17 deaths per 100,000) and 'vision zero' remains a Swedish dream [@johansson_vision_2009], we urge people researching STATS19 and other road safety datasets to focus on a more urgent question: how to stop this carnage?


```{r, include=FALSE, eval=FALSE}
# verify stats here (reproducible, they add-up)
# https://en.wikipedia.org/wiki/Reported_Road_Casualties_Great_Britain
1650 / 660 # death rate per person
c_j = inner_join(c, a)
sum(c$casualty_severity[grepl(pattern = 2017, as.character(c_j$date))] == "Fatal")
```

# Acknowldgements

The work was funded by the Leeds Insititute for Transport Studies (ITS) Consumer Data Resarch Center (CDRC) at Leeds Institute for Data Analytics (LIDA).
Thanks to open source software developers who made all this possbile, and to GitHub, where the source code behind this paper is hosted:  https://github.com/Robinlovelace/stats19-gisruk

<!-- wordcountaddin::text_stats("stats19-gisruk/README.Rmd") -->
# References